"""
Data Cleaning Module for Farmlands Analytics

This module contains functions for cleaning and preprocessing agricultural data.
Workshop participants will use AI tools to complete the TODO sections.
"""

import pandas as pd
import numpy as np
import logging
from typing import Optional, List, Tuple, Dict, Any
from pathlib import Path
from datetime import datetime
from sklearn.impute import SimpleImputer
import warnings
warnings.filterwarnings('ignore')


class FarmDataCleaner:
    """
    A comprehensive data cleaner for agricultural supply chain data.
    
    TODO: Workshop participants should use AI tools to implement the following methods:
    1. handle_missing_values()
    2. standardize_product_names()
    3. validate_farm_ids()
    4. clean_price_outliers()
    5. standardize_date_formats()
    """
    
    def __init__(self, data_path: str):
        """Initialize the cleaner with data path."""
        self.data_path = Path(data_path)
        self.raw_data = None
        self.cleaned_data = None
    
    def load_data(self, filename: str) -> pd.DataFrame:
        """Load raw data from CSV file."""
        file_path = self.data_path / filename
        try:
            self.raw_data = pd.read_csv(file_path)
            print(f"‚úÖ Successfully loaded {filename} with {len(self.raw_data)} rows")
            return self.raw_data
        except FileNotFoundError:
            raise FileNotFoundError(f"‚ùå Data file not found: {file_path}")
    
    def handle_missing_values(self, df: pd.DataFrame, strategy: str = "auto") -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """
        Comprehensive missing value handler for agricultural data with automatic strategy selection.
        
        Considers agricultural business context including seasonal patterns, product relationships,
        and regional variations specific to New Zealand farming operations.
        
        Args:
            df: Input dataframe
            strategy: Strategy for handling missing values ('auto', 'drop', 'fill_mean', 'fill_median', 'forward_fill')
            
        Returns:
            Tuple of (cleaned DataFrame, summary report of actions taken)
        """
        # Set up logging
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
        logger = logging.getLogger(__name__)
        
        logger.info("üåæ Starting agricultural data missing value analysis...")
        
        # Create a copy to avoid modifying original data
        df_cleaned = df.copy()
        
        # Initialize summary report
        summary_report = {
            'original_shape': df.shape,
            'columns_processed': [],
            'actions_taken': {},
            'missing_patterns': {},
            'agricultural_logic_applied': [],
            'warnings': [],
            'final_shape': None
        }
        
        # Analyze missing patterns
        missing_analysis = self._analyze_missing_patterns(df, logger)
        summary_report['missing_patterns'] = missing_analysis
        
        # Process each column based on strategy
        for column in df.columns:
            missing_count = df[column].isnull().sum()
            missing_percentage = (missing_count / len(df)) * 100
            
            if missing_count == 0:
                logger.info(f"‚úÖ {column}: No missing values")
                continue
                
            logger.info(f"üîç Processing {column}: {missing_count} missing ({missing_percentage:.1f}%)")
            
            # Determine strategy for this column
            if strategy == "auto":
                column_strategy = self._determine_auto_strategy(df, column, missing_percentage, logger)
            else:
                column_strategy = strategy
            
            # Apply the strategy
            df_cleaned, action_summary = self._apply_missing_strategy(
                df_cleaned, column, column_strategy, missing_percentage, logger
            )
            
            summary_report['columns_processed'].append(column)
            summary_report['actions_taken'][column] = action_summary
        
        # Apply agricultural business logic for validation and improvements
        df_cleaned, ag_logic_summary = self._apply_agricultural_logic(df_cleaned, logger)
        summary_report['agricultural_logic_applied'] = ag_logic_summary
        
        # Final validation
        df_cleaned = self._final_validation(df_cleaned, logger)
        summary_report['final_shape'] = df_cleaned.shape
        
        # Calculate improvement metrics
        original_completeness = (df.count().sum() / (df.shape[0] * df.shape[1])) * 100
        final_completeness = (df_cleaned.count().sum() / (df_cleaned.shape[0] * df_cleaned.shape[1])) * 100
        
        logger.info(f"üìä Data completeness improved from {original_completeness:.1f}% to {final_completeness:.1f}%")
        summary_report['completeness_improvement'] = final_completeness - original_completeness
        
        return df_cleaned, summary_report
    
    def _analyze_missing_patterns(self, df: pd.DataFrame, logger) -> Dict[str, Any]:
        """Analyze missing value patterns in the agricultural data."""
        patterns = {}
        
        for column in df.columns:
            missing_count = df[column].isnull().sum()
            missing_percentage = (missing_count / len(df)) * 100
            
            patterns[column] = {
                'missing_count': missing_count,
                'missing_percentage': missing_percentage,
                'data_type': str(df[column].dtype),
                'unique_values': df[column].nunique(),
                'completeness_category': self._categorize_completeness(missing_percentage)
            }
            
        logger.info(f"üìà Missing patterns analyzed for {len(df.columns)} columns")
        return patterns
    
    def _categorize_completeness(self, missing_percentage: float) -> str:
        """Categorize completeness levels for strategy selection."""
        if missing_percentage == 0:
            return "complete"
        elif missing_percentage < 5:
            return "excellent"
        elif missing_percentage < 20:
            return "good"
        elif missing_percentage < 50:
            return "moderate"
        else:
            return "poor"
    
    def _determine_auto_strategy(self, df: pd.DataFrame, column: str, missing_percentage: float, logger) -> str:
        """Automatically determine the best strategy based on column characteristics and agricultural context."""
        
        # Get column info
        dtype = df[column].dtype
        is_numeric = pd.api.types.is_numeric_dtype(df[column])
        is_datetime = pd.api.types.is_datetime64_any_dtype(df[column]) or 'date' in column.lower()
        is_categorical = df[column].dtype == 'object' and not is_datetime
        
        # Agricultural business logic for strategy selection
        if column in ['farm_id', 'region']:
            # Critical business identifiers - should rarely be missing
            if missing_percentage > 20:
                logger.warning(f"‚ö†Ô∏è High missing percentage for critical field {column}")
                return "drop_rows"
            else:
                return "unknown_category"
        
        elif column in ['product_name', 'product_category']:
            # Product information - use agricultural product relationships
            if missing_percentage < 10:
                return "agricultural_product_logic"
            else:
                return "unknown_category"
        
        elif column in ['quantity_sold', 'unit_price']:
            # Numerical business data
            if missing_percentage > 30:
                logger.warning(f"‚ö†Ô∏è High missing percentage for {column}, consider data source quality")
                return "median_with_validation"
            elif missing_percentage < 5:
                return "mean"
            else:
                return "median"
        
        elif 'date' in column.lower() or is_datetime:
            # Date fields - critical for seasonal analysis
            if missing_percentage > 10:
                return "drop_rows"
            else:
                return "interpolate_seasonal"
        
        elif column in ['season', 'weather_condition']:
            # Seasonal/environmental data
            return "seasonal_logic"
        
        # Default strategies based on data type
        elif is_numeric:
            if missing_percentage < 5:
                return "mean"
            elif missing_percentage < 20:
                return "median"
            else:
                return "median_with_validation"
        
        elif is_categorical:
            if missing_percentage < 10:
                return "mode"
            elif missing_percentage < 30:
                return "forward_fill"
            else:
                return "unknown_category"
        
        else:
            logger.warning(f"‚ö†Ô∏è Unknown data type for {column}, using conservative approach")
            return "drop_rows" if missing_percentage > 50 else "unknown_category"
    
    def _apply_missing_strategy(self, df: pd.DataFrame, column: str, strategy: str, 
                               missing_percentage: float, logger) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """Apply the determined strategy to handle missing values."""
        
        action_summary = {
            'strategy_used': strategy,
            'missing_before': df[column].isnull().sum(),
            'missing_percentage_before': missing_percentage,
            'action_details': '',
            'agricultural_context': ''
        }
        
        df_result = df.copy()
        
        try:
            if strategy == "drop_rows":
                rows_before = len(df_result)
                df_result = df_result.dropna(subset=[column])
                rows_dropped = rows_before - len(df_result)
                action_summary['action_details'] = f"Dropped {rows_dropped} rows with missing {column}"
                logger.info(f"üìâ Dropped {rows_dropped} rows due to missing {column}")
                
            elif strategy == "mean":
                if pd.api.types.is_numeric_dtype(df_result[column]):
                    fill_value = df_result[column].mean()
                    df_result.loc[:, column] = df_result[column].fillna(fill_value)
                    action_summary['action_details'] = f"Filled with mean value: {fill_value:.2f}"
                    logger.info(f"üìä Filled {column} with mean: {fill_value:.2f}")
                
            elif strategy == "median":
                if pd.api.types.is_numeric_dtype(df_result[column]):
                    fill_value = df_result[column].median()
                    df_result.loc[:, column] = df_result[column].fillna(fill_value)
                    action_summary['action_details'] = f"Filled with median value: {fill_value:.2f}"
                    logger.info(f"üìä Filled {column} with median: {fill_value:.2f}")
                
            elif strategy == "median_with_validation":
                if pd.api.types.is_numeric_dtype(df_result[column]):
                    # Use median but validate against business rules
                    median_val = df_result[column].median()
                    
                    # Agricultural validation - check if values are reasonable
                    if column == 'quantity_sold' and median_val > 10000:
                        logger.warning(f"‚ö†Ô∏è Large median quantity ({median_val}) - may indicate bulk sales")
                    elif column == 'unit_price' and median_val > 100:
                        logger.warning(f"‚ö†Ô∏è High median price ({median_val}) - verify premium products")
                    
                    df_result.loc[:, column] = df_result[column].fillna(median_val)
                    action_summary['action_details'] = f"Filled with validated median: {median_val:.2f}"
                    action_summary['agricultural_context'] = "Validated against agricultural business rules"
                
            elif strategy == "mode":
                if df_result[column].dtype == 'object':
                    mode_value = df_result[column].mode().iloc[0] if not df_result[column].mode().empty else "Unknown"
                    df_result.loc[:, column] = df_result[column].fillna(mode_value)
                    action_summary['action_details'] = f"Filled with mode value: {mode_value}"
                    logger.info(f"üìä Filled {column} with mode: {mode_value}")
                
            elif strategy == "forward_fill":
                # Sort by date for logical forward fill in agricultural context
                if 'sale_date' in df_result.columns:
                    df_result = df_result.sort_values('sale_date')
                df_result[column] = df_result[column].ffill()
                action_summary['action_details'] = "Applied forward fill (sorted by date)"
                action_summary['agricultural_context'] = "Maintained temporal agricultural patterns"
                
            elif strategy == "unknown_category":
                df_result.loc[:, column] = df_result[column].fillna("Unknown")
                action_summary['action_details'] = "Filled with 'Unknown' category"
                logger.info(f"üìù Filled {column} with 'Unknown' category")
                
            elif strategy == "agricultural_product_logic":
                # Apply agricultural product relationship logic
                df_result = self._apply_agricultural_product_logic(df_result, column, logger)
                action_summary['action_details'] = "Applied agricultural product relationship logic"
                action_summary['agricultural_context'] = "Used product category relationships and NZ agricultural knowledge"
                
            elif strategy == "seasonal_logic":
                # Apply seasonal agricultural logic
                df_result = self._apply_seasonal_logic(df_result, column, logger)
                action_summary['action_details'] = "Applied seasonal agricultural logic"
                action_summary['agricultural_context'] = "Used NZ agricultural calendar and seasonal patterns"
                
            elif strategy == "interpolate_seasonal":
                # Interpolate dates considering agricultural seasons
                if column == 'sale_date' or 'date' in column.lower():
                    df_result[column] = pd.to_datetime(df_result[column], errors='coerce')
                    
                    # For date interpolation, sort by existing dates and interpolate
                    if df_result[column].notna().any():
                        df_result = df_result.sort_values(column, na_position='last')
                        df_result[column] = df_result[column].interpolate(method='time')
                        action_summary['action_details'] = "Applied seasonal date interpolation"
                        action_summary['agricultural_context'] = "Maintained agricultural seasonal continuity"
                    else:
                        # If no valid dates, fall back to unknown
                        df_result.loc[:, column] = df_result[column].fillna("Unknown")
                        action_summary['action_details'] = "No valid dates for interpolation, filled with Unknown"
            
            # Update final missing count
            action_summary['missing_after'] = df_result[column].isnull().sum()
            action_summary['missing_percentage_after'] = (action_summary['missing_after'] / len(df_result)) * 100
            
        except Exception as e:
            logger.error(f"‚ùå Error applying strategy {strategy} to {column}: {str(e)}")
            action_summary['error'] = str(e)
            
        return df_result, action_summary
    
    def _apply_agricultural_product_logic(self, df: pd.DataFrame, column: str, logger) -> pd.DataFrame:
        """Apply agricultural domain knowledge to infer missing product information."""
        
        if column == 'product_name' and 'product_category' in df.columns:
            # Map product categories to common NZ agricultural products
            ag_product_mapping = {
                'Fertilizer': ['Urea 46%', 'DAP 18-46-0', 'NPK 15-15-15', 'Superphosphate', 'Lime Agricultural'],
                'Seeds': ['Ryegrass Premium', 'Clover White', 'Maize Hybrid', 'Oats Premium'],
                'Pesticides': ['Glyphosate 360', 'Roundup Ready', 'Copper Sulfate'],
                'Animal Feed': ['Barley Feed', 'Lucerne Hay', 'Sheep Pellets', 'Molasses Block'],
                'Tools': ['Spade Premium', 'Pruning Shears', 'Irrigation Pipe']
            }
            
            for idx, row in df.iterrows():
                if pd.isna(row[column]) and not pd.isna(row['product_category']):
                    category = row['product_category']
                    if category in ag_product_mapping:
                        # Use most common product for the category
                        common_product = ag_product_mapping[category][0]
                        df.at[idx, column] = common_product
                        logger.info(f"üåæ Inferred {column}: {common_product} from category {category}")
        
        return df
    
    def _apply_seasonal_logic(self, df: pd.DataFrame, column: str, logger) -> pd.DataFrame:
        """Apply New Zealand agricultural seasonal logic."""
        
        if column == 'weather_condition' and 'season' in df.columns:
            # Map seasons to typical NZ weather patterns
            seasonal_weather_mapping = {
                'Summer': ['Sunny', 'Hot', 'Warm', 'Dry'],
                'Autumn': ['Mild', 'Rainy', 'Cloudy'],
                'Winter': ['Cold', 'Rainy', 'Frost', 'Cool'],
                'Spring': ['Mild', 'Windy', 'Sunny', 'Rainy']
            }
            
            for idx, row in df.iterrows():
                if pd.isna(row[column]) and not pd.isna(row['season']):
                    season = row['season']
                    if season in seasonal_weather_mapping:
                        # Use most common weather for the season
                        typical_weather = seasonal_weather_mapping[season][0]
                        df.at[idx, column] = typical_weather
                        logger.info(f"üå§Ô∏è Inferred {column}: {typical_weather} for {season} season")
        
        elif column == 'season' and 'sale_date' in df.columns:
            # Infer season from sale date using NZ agricultural calendar
            for idx, row in df.iterrows():
                if pd.isna(row[column]) and not pd.isna(row['sale_date']):
                    try:
                        date = pd.to_datetime(row['sale_date'])
                        month = date.month
                        
                        # NZ seasons (Southern Hemisphere)
                        if month in [12, 1, 2]:
                            season = 'Summer'
                        elif month in [3, 4, 5]:
                            season = 'Autumn'
                        elif month in [6, 7, 8]:
                            season = 'Winter'
                        else:  # 9, 10, 11
                            season = 'Spring'
                            
                        df.at[idx, column] = season
                        logger.info(f"üìÖ Inferred season: {season} from date {row['sale_date']}")
                    except:
                        pass
        
        return df
    
    def _apply_agricultural_logic(self, df: pd.DataFrame, logger) -> Tuple[pd.DataFrame, List[str]]:
        """Apply final agricultural business logic and validation."""
        agricultural_actions = []
        
        # 1. Validate quantity-price relationships
        if 'quantity_sold' in df.columns and 'unit_price' in df.columns:
            # Check for unrealistic combinations
            high_qty_high_price = df[(df['quantity_sold'] > df['quantity_sold'].quantile(0.9)) & 
                                   (df['unit_price'] > df['unit_price'].quantile(0.9))]
            
            if len(high_qty_high_price) > 0:
                logger.warning(f"‚ö†Ô∏è Found {len(high_qty_high_price)} records with both high quantity and high price")
                agricultural_actions.append(f"Flagged {len(high_qty_high_price)} potential bulk premium sales")
        
        # 2. Validate seasonal product alignment
        if 'product_category' in df.columns and 'season' in df.columns:
            # Check for seasonal appropriateness
            seasonal_mismatches = 0
            for idx, row in df.iterrows():
                if row['product_category'] == 'Seeds' and row['season'] == 'Winter':
                    logger.info(f"‚ÑπÔ∏è Winter seed sales detected - possibly for next season planning")
                    seasonal_mismatches += 1
            
            if seasonal_mismatches > 0:
                agricultural_actions.append(f"Validated {seasonal_mismatches} winter seed sales as forward planning")
        
        # 3. Regional product validation
        if 'region' in df.columns and 'product_category' in df.columns:
            regional_patterns = df.groupby(['region', 'product_category']).size().reset_index(name='count')
            agricultural_actions.append(f"Validated regional product patterns across {len(regional_patterns)} combinations")
        
        logger.info(f"üåæ Applied {len(agricultural_actions)} agricultural business logic validations")
        return df, agricultural_actions
    
    def _final_validation(self, df: pd.DataFrame, logger) -> pd.DataFrame:
        """Perform final validation and cleanup."""
        
        # Check for any remaining critical missing values
        critical_columns = ['farm_id', 'region', 'product_category']
        for col in critical_columns:
            if col in df.columns:
                missing_critical = df[col].isnull().sum()
                if missing_critical > 0:
                    logger.warning(f"‚ö†Ô∏è {missing_critical} missing values remain in critical column {col}")
        
        # Ensure data types are appropriate
        if 'sale_date' in df.columns:
            df['sale_date'] = pd.to_datetime(df['sale_date'], errors='coerce')
        
        if 'quantity_sold' in df.columns:
            df['quantity_sold'] = pd.to_numeric(df['quantity_sold'], errors='coerce')
        
        if 'unit_price' in df.columns:
            df['unit_price'] = pd.to_numeric(df['unit_price'], errors='coerce')
        
        logger.info("‚úÖ Final validation completed")
        return df

    def standardize_product_names(self, df: pd.DataFrame, column: str = "product_name") -> pd.DataFrame:
        """
        Standardize agricultural product names for consistency and analysis.
        
        This method cleans and standardizes product names to ensure consistency
        across the dataset, which is crucial for accurate agricultural supply
        chain analysis and inventory management.
        
        The standardization process includes:
        - Removing extra whitespace and special characters
        - Normalizing capitalization patterns
        - Grouping similar product variations under standard names
        - Applying agricultural domain knowledge for product categorization
        - Creating mappings for common abbreviations and variations
        
        Args:
            df (pd.DataFrame): Input dataframe containing product data
            column (str): Column name containing product names to standardize
            
        Returns:
            pd.DataFrame: DataFrame with standardized product names and 
                         additional metadata columns for mapping tracking
                         
        Raises:
            ValueError: If specified column doesn't exist in dataframe
            TypeError: If input is not a pandas DataFrame
            
        Example:
            >>> cleaner = FarmDataCleaner("data/")
            >>> df = pd.DataFrame({'product_name': ['UREA 46%', 'urea 46%', 'Urea-46']})
            >>> standardized_df = cleaner.standardize_product_names(df)
            >>> print(standardized_df['product_name'].unique())
            ['Urea 46%']
        
        Note:
            This implementation is designed for New Zealand agricultural
            products and may need adaptation for other regions.
        """
        # TODO: Implement product name standardization logic
        # Workshop participants should use AI to implement this method
        print("üîÑ Product name standardization not yet implemented")
        print("   Use AI tools to implement this functionality")
        return df
    
    def validate_farm_ids(self, df: pd.DataFrame, farm_id_column: str = "farm_id") -> Tuple[pd.DataFrame, List[str]]:
        """
        Validate and clean farm IDs according to Farmlands standards.
        
        This method ensures farm IDs conform to expected formats and patterns,
        which is essential for accurate customer identification and data integrity
        in agricultural supply chain management.
        
        Validation checks include:
        - Format compliance (F### pattern where ### is 3 digits)
        - Detection of suspicious or invalid entries
        - Cross-referencing with master farm databases when available
        - Identification of potential data entry errors
        - Duplicate ID detection within the dataset
        
        Args:
            df (pd.DataFrame): Input dataframe containing farm data
            farm_id_column (str): Column name containing farm IDs to validate
            
        Returns:
            Tuple[pd.DataFrame, List[str]]: A tuple containing:
                - Cleaned dataframe with validated farm IDs
                - List of validation issues found during processing
                
        Raises:
            ValueError: If specified column doesn't exist in dataframe
            TypeError: If input is not a pandas DataFrame
            
        Example:
            >>> cleaner = FarmDataCleaner("data/")
            >>> df = pd.DataFrame({'farm_id': ['F001', 'F999', 'Invalid', 'F1234']})
            >>> clean_df, issues = cleaner.validate_farm_ids(df)
            >>> print(issues)
            ['Invalid farm ID format: Invalid', 'Farm ID too long: F1234']
        
        Note:
            This method follows Farmlands Co-operative's farm identification
            standards specific to New Zealand agricultural operations.
        """
        # TODO: Implement farm ID validation logic
        # Workshop participants should use AI to implement this method
        issues = []
        print("üîÑ Farm ID validation not yet implemented")
        print("   Use AI tools to implement this functionality")
        return df, issues
    
    def clean_price_outliers(self, df: pd.DataFrame, price_column: str = "unit_price", 
                            method: str = "iqr") -> pd.DataFrame:
        """
        Detect and clean price outliers in agricultural product data.
        
        This method identifies and handles unusual pricing data that could
        indicate data entry errors, special pricing conditions, or market
        anomalies. Proper outlier handling is crucial for accurate financial
        analysis and pricing models in agricultural supply chains.
        
        Outlier detection methods available:
        - 'iqr': Interquartile Range method (1.5 * IQR rule)
        - 'zscore': Z-score method (|z| > 3 threshold)
        - 'isolation_forest': Machine learning based isolation forest
        - 'modified_zscore': Modified Z-score using median absolute deviation
        
        Args:
            df (pd.DataFrame): Input dataframe containing pricing data
            price_column (str): Column name containing unit prices
            method (str): Method for outlier detection (default: 'iqr')
            
        Returns:
            pd.DataFrame: DataFrame with outliers handled through capping,
                         removal, or flagging based on agricultural business rules
                         
        Raises:
            ValueError: If specified price column doesn't exist or method is invalid
            TypeError: If input is not a pandas DataFrame
            
        Example:
            >>> cleaner = FarmDataCleaner("data/")
            >>> df = pd.DataFrame({'unit_price': [10, 12, 15, 1000, 8]})
            >>> clean_df = cleaner.clean_price_outliers(df, method='iqr')
            >>> print(clean_df['unit_price'].max())  # Outlier capped or removed
            
        Note:
            Price outlier detection considers product categories and seasonal
            variations typical in New Zealand agricultural markets.
        """
        # TODO: Implement price outlier cleaning logic
        # Workshop participants should use AI to implement this method
        print("üîÑ Price outlier cleaning not yet implemented")
        print("   Use AI tools to implement this functionality")
        return df
    
    def standardize_date_formats(self, df: pd.DataFrame, date_columns: Optional[List[str]] = None) -> pd.DataFrame:
        """
        Standardize date formats and create agricultural calendar features.
        
        This method ensures all date columns follow consistent formats and
        creates additional time-based features relevant to agricultural
        analysis, including seasonal indicators specific to New Zealand's
        agricultural calendar.
        
        Standardization includes:
        - Auto-detection of date columns if not specified
        - Parsing various date formats (DD/MM/YYYY, YYYY-MM-DD, etc.)
        - Handling invalid or ambiguous date entries
        - Creating derived features (year, month, quarter, season)
        - Adding agricultural calendar indicators (planting/harvest seasons)
        - Time zone normalization for New Zealand operations
        
        Args:
            df (pd.DataFrame): Input dataframe containing date columns
            date_columns (Optional[List[str]]): Specific date columns to process.
                                              If None, auto-detects date columns
            
        Returns:
            pd.DataFrame: DataFrame with standardized dates and additional
                         time-based features for agricultural analysis
                         
        Raises:
            ValueError: If specified date columns don't exist
            TypeError: If input is not a pandas DataFrame
            
        Example:
            >>> cleaner = FarmDataCleaner("data/")
            >>> df = pd.DataFrame({'sale_date': ['01/03/2023', '2023-03-15']})
            >>> clean_df = cleaner.standardize_date_formats(df)
            >>> print(clean_df['sale_date_season'].unique())
            ['Autumn']
        
        Note:
            Seasonal mapping follows New Zealand's agricultural calendar:
            Summer (Dec-Feb), Autumn (Mar-May), Winter (Jun-Aug), Spring (Sep-Nov)
        """
        # TODO: Implement date standardization logic
        # Workshop participants should use AI to implement this method
        print("üîÑ Date standardization not yet implemented")
        print("   Use AI tools to implement this functionality")
        return df
    
    def run_full_cleaning_pipeline(self, input_file: str, output_file: Optional[str] = None) -> pd.DataFrame:
        """
        Execute the complete data cleaning pipeline for agricultural data.
        
        This method orchestrates all cleaning steps in the optimal order,
        providing comprehensive data preprocessing for agricultural supply
        chain analysis. The pipeline follows best practices for data quality
        improvement while preserving agricultural business context.
        
        Pipeline stages:
        1. Data loading and initial validation
        2. Missing value handling with agricultural logic
        3. Farm ID validation and standardization
        4. Product name standardization
        5. Price outlier detection and cleaning
        6. Date format standardization
        7. Final quality validation
        8. Report generation and data export
        
        Args:
            input_file (str): Name of the input CSV file in the data directory
            output_file (Optional[str]): Path for saving cleaned data. If None,
                                       data is not saved to file
            
        Returns:
            pd.DataFrame: Fully cleaned and validated agricultural dataset
            
        Raises:
            FileNotFoundError: If input file cannot be located
            ValueError: If data validation fails critically
            
        Example:
            >>> cleaner = FarmDataCleaner("data/raw/")
            >>> clean_data = cleaner.run_full_cleaning_pipeline(
            ...     "farm_supply_data.csv", 
            ...     "data/processed/farm_supply_clean.csv"
            ... )
            >>> print(f"Cleaned dataset shape: {clean_data.shape}")
        
        Note:
            This pipeline is optimized for New Zealand agricultural data
            and follows Farmlands Co-operative data quality standards.
        """
        print("üöÄ Starting Farmlands data cleaning pipeline...")
        
        # TODO: Implement full pipeline
        # Workshop participants should use AI to implement this method
        print("üîÑ Full cleaning pipeline not yet implemented")
        print("   Use AI tools to implement this comprehensive workflow")
        print("   Suggested implementation order:")
        print("   1. Load data")
        print("   2. Handle missing values")
        print("   3. Validate farm IDs") 
        print("   4. Standardize product names")
        print("   5. Clean price outliers")
        print("   6. Standardize dates")
        print("   7. Generate report")
        print("   8. Save cleaned data")
        
        # Return empty DataFrame as placeholder
        return pd.DataFrame()


def generate_data_quality_report(df: pd.DataFrame) -> Dict[str, Any]:
    """
    Generate comprehensive data quality report for agricultural datasets.
    
    This function analyzes data quality across multiple dimensions to provide
    actionable insights for data improvement and validation. The report is
    specifically tailored for agricultural supply chain data with relevant
    business context and quality thresholds.
    
    Quality metrics include:
    - Completeness analysis (missing value patterns)
    - Uniqueness assessment (duplicate detection)
    - Validity checks (format compliance, range validation)
    - Consistency analysis (cross-field validation)
    - Distribution analysis (statistical summaries)
    - Agricultural business rule validation
    
    Args:
        df (pd.DataFrame): Input dataframe to analyze for quality metrics
        
    Returns:
        Dict[str, Any]: Comprehensive quality report containing:
            - completeness_metrics: Missing value analysis by column
            - uniqueness_metrics: Duplicate and cardinality analysis
            - validity_metrics: Format and range validation results
            - distribution_metrics: Statistical summaries and outliers
            - business_rules_validation: Agricultural domain checks
            - overall_quality_score: Aggregated quality assessment
            
    Raises:
        TypeError: If input is not a pandas DataFrame
        ValueError: If dataframe is empty
        
    Example:
        >>> df = pd.read_csv("farm_supply_data.csv")
        >>> quality_report = generate_data_quality_report(df)
        >>> print(f"Overall quality: {quality_report['overall_quality_score']:.1f}%")
        >>> print(f"Missing data issues: {len(quality_report['completeness_metrics'])}")
    
    Note:
        Quality thresholds and business rules are calibrated for New Zealand
        agricultural data patterns and Farmlands operational requirements.
    """
    # TODO: Implement quality reporting logic
    # Workshop participants should use AI to implement this function
    print("üîÑ Data quality reporting not yet implemented")
    print("   Use AI tools to implement comprehensive quality analysis")
    return {
        'status': 'not_implemented',
        'message': 'Quality reporting functionality needs to be implemented'
    }


# Example usage for workshop participants
if __name__ == "__main__":
    # Workshop participants can run this to test their implementations
    
    print("üåæ Farmlands Data Cleaning Workshop")
    print("=" * 50)
    
    # TODO: Workshop participants should complete the cleaner implementation
    # and then uncomment and run the following code:
    
    """
    cleaner = FarmDataCleaner("../../../data/raw")
    
    # Clean the farm supply data
    cleaned_data = cleaner.run_full_cleaning_pipeline(
        input_file="farm_supply_data.csv",
        output_file="../../../data/processed/farm_supply_cleaned.csv"
    )
    
    # Generate data quality report
    quality_report = generate_data_quality_report(cleaned_data)
    print("üìä Data Quality Report:")
    for metric, value in quality_report.items():
        print(f"  {metric}: {value}")
    """
    
    print("\nüéØ TODO: Use AI tools to implement the cleaning methods above!")
    print("üí° Hint: Start with handle_missing_values() method")